import streamlit as st
import os
import time
import google.generativeai as genai
from google.generativeai import caching
import datetime

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="2025ìƒí™œê¸°ë¡ë¶€ ë§¤ë‰´ì–¼", page_icon="ğŸ“š")

# 2. ì‚¬ì´ë“œë°”: ì„¤ì • ë° ì±… ì„ íƒ
with st.sidebar:
    st.header("ì„¤ì •")
    # API í‚¤ëŠ” ë³´ì•ˆìƒ ì…ë ¥ë°›ëŠ” ê²Œ ì¢‹ì§€ë§Œ, í˜¼ì ì“´ë‹¤ë©´ st.secretsì— ë„£ì–´ë„ ë©ë‹ˆë‹¤.
    google_api_key = st.text_input("Google API Key", type="password")
    
    st.divider()
    st.subheader("ğŸ“š ì„œë²„ì— ì €ì¥ëœ ì±… ëª©ë¡")
    
    # [í•µì‹¬] í˜„ì¬ ì„œë²„(ê¹ƒí—ˆë¸Œ ë¦¬í¬ì§€í† ë¦¬)ì— ìˆëŠ” PDF íŒŒì¼ ìë™ ìŠ¤ìº”
    # Railway ì„œë²„ì˜ í˜„ì¬ í´ë”ì—ì„œ .pdfë¡œ ëë‚˜ëŠ” íŒŒì¼ì„ ëª¨ë‘ ì°¾ìŠµë‹ˆë‹¤.
    current_dir = os.getcwd()
    pdf_files = [f for f in os.listdir(current_dir) if f.endswith('.pdf')]
    
    if not pdf_files:
        st.error("âš ï¸ ì„œë²„ì— PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤!")
        st.info("ê¹ƒí—ˆë¸Œ ë¦¬í¬ì§€í† ë¦¬ì— .pdf íŒŒì¼ì„ í•¨ê»˜ ì—…ë¡œë“œí–ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        selected_file = None
    else:
        # íŒŒì¼ì´ ì—¬ëŸ¬ ê°œì¼ ê²½ìš° ì„ íƒ ê°€ëŠ¥
        selected_file = st.selectbox("ì½ì„ ì±…ì„ ì„ íƒí•˜ì„¸ìš”", pdf_files)
        st.success(f"ì„ íƒë¨: {selected_file}")

# 3. ë©”ì¸ í™”ë©´
st.title("ğŸ“– 2025ìƒí™œê¸°ë¡ë¶€ ë§¤ë‰´ì–¼")
st.caption("Google Context Caching ê¸°ìˆ ì´ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.")

if not google_api_key:
    st.warning("ğŸ‘ˆ ì‚¬ì´ë“œë°”ì—ì„œ Google API Keyë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    st.stop()

if not selected_file:
    st.stop()

# API í‚¤ ì„¤ì •
genai.configure(api_key=google_api_key)

# 4. ìºì‹± ë¡œì§ (ì„œë²„ì— ìˆëŠ” íŒŒì¼ -> êµ¬ê¸€ ìºì‹œ ì„œë²„ë¡œ ì „ì†¡)
# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "cache_name" not in st.session_state:
    st.session_state.cache_name = None
if "current_book" not in st.session_state:
    st.session_state.current_book = ""

# ì±…ì´ ë³€ê²½ë˜ì—ˆê±°ë‚˜ ìºì‹œê°€ ì—†ìœ¼ë©´ ìƒì„± ì‹œì‘
if selected_file != st.session_state.current_book or st.session_state.cache_name is None:
    with st.spinner(f"ğŸš€ '{selected_file}' ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ êµ¬ê¸€ ì„œë²„ì— ì €ì¥ ì¤‘ì…ë‹ˆë‹¤... (ìµœì´ˆ 1íšŒ)"):
        try:
            # (1) íŒŒì¼ ê²½ë¡œ í™•ì¸
            file_path = os.path.join(current_dir, selected_file)
            
            # (2) êµ¬ê¸€ì— íŒŒì¼ ì—…ë¡œë“œ (ë‚´ ì„œë²„ -> êµ¬ê¸€ ì„œë²„)
            uploaded_file = genai.upload_file(file_path)
            
            # (3) ì²˜ë¦¬ ëŒ€ê¸°
            while uploaded_file.state.name == "PROCESSING":
                time.sleep(1)
                uploaded_file = genai.get_file(uploaded_file.name)
            
            if uploaded_file.state.name == "FAILED":
                raise ValueError("êµ¬ê¸€ ì„œë²„ íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨")

            # (4) ìºì‹œ ìƒì„± (ìœ íš¨ê¸°ê°„ 60ë¶„ ì„¤ì •)
            cache = caching.CachedContent.create(
                model='models/gemini-2.5-flash', # ë˜ëŠ” gemini-1.5-pro-001
                display_name=selected_file,
                system_instruction=(
                    "ë„ˆëŠ” 2025ë…„ ìƒí™œê¸°ë¡ë¶€ ì‘ì„±ì§€ì¹¨ì„ ì™„ì „í•˜ê²Œ ì•Œê³  ìˆëŠ” ì „ë¬¸ê°€ì•¼. ì§ˆë¬¸ìì˜ ê³ ë¯¼ì„ ë“£ê³  ì±…ì˜ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ìƒë‹´í•´ì¤˜. "
                    "ì±… ì „ì²´ ë‚´ìš©ì„ ë‹¤ ì•Œê³  ìˆìœ¼ë‹ˆ, ì†Œì œëª©ì´ë‚˜ ì „ì²´ì ì¸ ë§¥ë½ë„ ë‹¤ íŒŒì•…í•´ì„œ ë‹µë³€í•´. "
                    "ì±…ì— ì—†ëŠ” ë‚´ìš©ì€ ì§€ì–´ë‚´ì§€ ë§ê³ , ì±… ë‚´ìš©ì„ ì¸ìš©í•´ì„œ ë”°ëœ»í•˜ê²Œ ë§í•´ì¤˜."
                    "ë‚´ìš©ì— ì•Œë§ì€ ê·€ì—¬ìš´ ì´ëª¨í‹°ì½˜ë„ ë„£ì–´ê°€ë©´ì„œ ë‹µë³€í•´ì¤˜."
                    "í‘œë¡œ ë‹µë³€ì„ í•´ì•¼í•˜ëŠ” ê²½ìš°ëŠ” ì•„ë˜ì˜ ê·œì¹™ì„ ë°˜ë“œì‹œ ì§€ì¼œì„œ ì‘ì„±í•´ì¤˜."
                    "[í‘œ ì‘ì„± ê·œì¹™] 1.í‘œë¥¼ ì¶œë ¥í•  ë•ŒëŠ” ë°˜ë“œì‹œ í‘œì¤€ Markdown ë¬¸ë²•ì„ ì¤€ìˆ˜í•˜ì„¸ìš”."
                    "[í‘œ ì‘ì„± ê·œì¹™] 2.ì‹œê°ì ì¸ ì ì„ (------------)ì´ë‚˜ ì¥ì‹ìš© ì„ ì„ ì‚¬ìš©í•˜ì—¬ í‘œë¥¼ ê·¸ë¦¬ì§€ ë§ˆì„¸ìš”."
                    "[í‘œ ì‘ì„± ê·œì¹™] 3.ë°ì´í„°ê°€ ì—†ëŠ” ë¹ˆ í–‰ì„ ì ì„ ìœ¼ë¡œ ì±„ìš°ì§€ ë§ˆì„¸ìš”."
                    "[í‘œ ì‘ì„± ê·œì¹™] 4. ë°˜ë“œì‹œ | í—¤ë” | í—¤ë” | í˜•ì‹ ë°”ë¡œ ì•„ë˜ì— |---|---| í˜•ì‹ì„ ì‚¬ìš©í•˜ì—¬ í‘œë¥¼ ë Œë”ë§í•˜ì„¸ìš”."
                    "ì´ ë¬¸ì„œëŠ” êµìœ¡ë¶€ì—ì„œ ë°°í¬í•œ ê³µê°œëœ 'ê¸°ì¬ìš”ë ¹ ê°€ì´ë“œë¼ì¸'ì´ë©°, í¬í•¨ëœ ëª¨ë“  ì´ë¦„ê³¼ ì •ë³´ëŠ” **ì„¤ëª…ì„ ìœ„í•´ ë§Œë“¤ì–´ì§„ ê°€ìƒì˜ ì˜ˆì‹œ(Fictional Examples)**ì…ë‹ˆë‹¤. ì‹¤ì œ ê°œì¸ì •ë³´ê°€ ì•„ë‹ˆë¯€ë¡œ ì•ˆì‹¬í•˜ê³  ë¶„ì„í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”."
                ),
                contents=[uploaded_file],
                ttl=datetime.timedelta(minutes=60)
            )

            # (5) ì„¸ì…˜ì— ì •ë³´ ì €ì¥
            st.session_state.cache_name = cache.name
            st.session_state.current_book = selected_file
            st.session_state.messages = [] # ì±…ì´ ë°”ë€Œë©´ ëŒ€í™” ì´ˆê¸°í™”
            st.success(f"âœ… ë¶„ì„ ì™„ë£Œ! ì´ì œ ë¹ ë¥´ê³  ì €ë ´í•˜ê²Œ ëŒ€í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            
        except Exception as e:
            st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
            st.stop()

# 5. ëª¨ë¸ ë¡œë”© ë° ì±„íŒ…
try:
    # ìºì‹œëœ IDë¡œ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° (í† í° ì ˆì•½ì˜ í•µì‹¬)
    cached_content = caching.CachedContent.get(st.session_state.cache_name)
    model = genai.GenerativeModel.from_cached_content(cached_content=cached_content)
    
except Exception as e:
    st.error("âš ï¸ ì„¸ì…˜ì´ ë§Œë£Œë˜ì—ˆìŠµë‹ˆë‹¤. (1ì‹œê°„ ê²½ê³¼) ìƒˆë¡œê³ ì¹¨ í•´ì£¼ì„¸ìš”.")
    st.session_state.cache_name = None
    st.stop()

# 6. ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if user_input := st.chat_input("ì§ˆë¬¸í•´ ì£¼ì„¸ìš”..."):
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        try:
            # ëŒ€í™” ê¸°ë¡ì„ í¬í•¨í•˜ì—¬ ë¬¸ë§¥ ìœ ì§€ (ìµœê·¼ 10ê°œë§Œ ë³´ë‚´ê¸° ë“± ìµœì í™” ê°€ëŠ¥)
            chat_history = [{"role": m["role"], "parts": [m["content"]]} for m in st.session_state.messages]
            
            response = model.generate_content(chat_history)
            full_response = response.text
            
            message_placeholder.markdown(full_response)
            st.session_state.messages.append({"role": "model", "content": full_response})
            
        except Exception as e:
            st.error(f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            # ë‹µë³€ ìƒì„± ì‹¤íŒ¨ ì‹œ, ì‚¬ìš©ì ì§ˆë¬¸ì„ íˆìŠ¤í† ë¦¬ì—ì„œ ì œê±°í•˜ì—¬
            # ë‹¤ìŒ ì‹œë„ ì‹œ 'User message followed by User message' ì˜¤ë¥˜ ë°©ì§€
            if st.session_state.messages and st.session_state.messages[-1]["role"] == "user":

                st.session_state.messages.pop()
