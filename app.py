import streamlit as st
import os
import time
import google.generativeai as genai
from google.generativeai import caching
import datetime

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="AI ì €ìì™€ì˜ ëŒ€í™” (Server Ver.)", page_icon="ğŸ“š")

# 2. ì‚¬ì´ë“œë°”: ì„¤ì • ë° ì±… ì„ íƒ
with st.sidebar:
    st.header("ì„¤ì •")
    # API í‚¤ëŠ” ë³´ì•ˆìƒ ì…ë ¥ë°›ëŠ” ê²Œ ì¢‹ì§€ë§Œ, í˜¼ì ì“´ë‹¤ë©´ st.secretsì— ë„£ì–´ë„ ë©ë‹ˆë‹¤.
    google_api_key = st.text_input("Google API Key", type="password")
    
    st.divider()
    st.subheader("ğŸ“š ì„œë²„ì— ì €ì¥ëœ ì±… ëª©ë¡")
    
    # [í•µì‹¬] í˜„ì¬ ì„œë²„(ê¹ƒí—ˆë¸Œ ë¦¬í¬ì§€í† ë¦¬)ì— ìˆëŠ” PDF íŒŒì¼ ìë™ ìŠ¤ìº”
    # Railway ì„œë²„ì˜ í˜„ì¬ í´ë”ì—ì„œ .pdfë¡œ ëë‚˜ëŠ” íŒŒì¼ì„ ëª¨ë‘ ì°¾ìŠµë‹ˆë‹¤.
    current_dir = os.getcwd()
    pdf_files = [f for f in os.listdir(current_dir) if f.endswith('.pdf')]
    
    if not pdf_files:
        st.error("âš ï¸ ì„œë²„ì— PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤!")
        st.info("ê¹ƒí—ˆë¸Œ ë¦¬í¬ì§€í† ë¦¬ì— .pdf íŒŒì¼ì„ í•¨ê»˜ ì—…ë¡œë“œí–ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        selected_file = None
    else:
        # íŒŒì¼ì´ ì—¬ëŸ¬ ê°œì¼ ê²½ìš° ì„ íƒ ê°€ëŠ¥
        selected_file = st.selectbox("ì½ì„ ì±…ì„ ì„ íƒí•˜ì„¸ìš”", pdf_files)
        st.success(f"ì„ íƒë¨: {selected_file}")

# 3. ë©”ì¸ í™”ë©´
st.title("ğŸ“– AI ì €ìì™€ì˜ ì¸ìƒ ìƒë‹´ì†Œ")
st.caption("Google Context Caching ê¸°ìˆ ì´ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.")

if not google_api_key:
    st.warning("ğŸ‘ˆ ì‚¬ì´ë“œë°”ì—ì„œ Google API Keyë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    st.stop()

if not selected_file:
    st.stop()

# API í‚¤ ì„¤ì •
genai.configure(api_key=google_api_key)

# 4. ìºì‹± ë¡œì§ (ì„œë²„ì— ìˆëŠ” íŒŒì¼ -> êµ¬ê¸€ ìºì‹œ ì„œë²„ë¡œ ì „ì†¡)
# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "cache_name" not in st.session_state:
    st.session_state.cache_name = None
if "current_book" not in st.session_state:
    st.session_state.current_book = ""

# ì±…ì´ ë³€ê²½ë˜ì—ˆê±°ë‚˜ ìºì‹œê°€ ì—†ìœ¼ë©´ ìƒì„± ì‹œì‘
if selected_file != st.session_state.current_book or st.session_state.cache_name is None:
    with st.spinner(f"ğŸš€ '{selected_file}' ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ êµ¬ê¸€ ì„œë²„ì— ì €ì¥ ì¤‘ì…ë‹ˆë‹¤... (ìµœì´ˆ 1íšŒ)"):
        try:
            # (1) íŒŒì¼ ê²½ë¡œ í™•ì¸
            file_path = os.path.join(current_dir, selected_file)
            
            # (2) êµ¬ê¸€ì— íŒŒì¼ ì—…ë¡œë“œ (ë‚´ ì„œë²„ -> êµ¬ê¸€ ì„œë²„)
            uploaded_file = genai.upload_file(file_path)
            
            # (3) ì²˜ë¦¬ ëŒ€ê¸°
            while uploaded_file.state.name == "PROCESSING":
                time.sleep(1)
                uploaded_file = genai.get_file(uploaded_file.name)
            
            if uploaded_file.state.name == "FAILED":
                raise ValueError("êµ¬ê¸€ ì„œë²„ íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨")

            # (4) ìºì‹œ ìƒì„± (ìœ íš¨ê¸°ê°„ 60ë¶„ ì„¤ì •)
            cache = caching.CachedContent.create(
                model='models/gemini-1.5-flash-001', # ë˜ëŠ” gemini-1.5-pro-001
                display_name=selected_file,
                system_instruction=(
                    "ë„ˆëŠ” ì´ ì±…ì„ ì“´ ì €ìì•¼. ë…ìì˜ ê³ ë¯¼ì„ ë“£ê³  ì±…ì˜ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ìƒë‹´í•´ì¤˜. "
                    "ì±…ì˜ êµ¬ì²´ì ì¸ êµ¬ì ˆì´ë‚˜ ì‚¬ë¡€ë¥¼ ì¸ìš©í•´ì„œ ë‹µë³€í•˜ë©´ ë” ì¢‹ì•„. "
                    "ë”°ëœ»í•˜ê³  í†µì°°ë ¥ ìˆëŠ” ì–´ì¡°ë¥¼ ìœ ì§€í•´ì¤˜."
                ),
                contents=[uploaded_file],
                ttl=datetime.timedelta(minutes=60)
            )

            # (5) ì„¸ì…˜ì— ì •ë³´ ì €ì¥
            st.session_state.cache_name = cache.name
            st.session_state.current_book = selected_file
            st.session_state.messages = [] # ì±…ì´ ë°”ë€Œë©´ ëŒ€í™” ì´ˆê¸°í™”
            st.success(f"âœ… ë¶„ì„ ì™„ë£Œ! ì´ì œ ë¹ ë¥´ê³  ì €ë ´í•˜ê²Œ ëŒ€í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            
        except Exception as e:
            st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
            st.stop()

# 5. ëª¨ë¸ ë¡œë”© ë° ì±„íŒ…
try:
    # ìºì‹œëœ IDë¡œ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° (í† í° ì ˆì•½ì˜ í•µì‹¬)
    cached_content = caching.CachedContent.get(st.session_state.cache_name)
    model = genai.GenerativeModel.from_cached_content(cached_content=cached_content)
    
except Exception as e:
    st.error("âš ï¸ ì„¸ì…˜ì´ ë§Œë£Œë˜ì—ˆìŠµë‹ˆë‹¤. (1ì‹œê°„ ê²½ê³¼) ìƒˆë¡œê³ ì¹¨ í•´ì£¼ì„¸ìš”.")
    st.session_state.cache_name = None
    st.stop()

# 6. ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if user_input := st.chat_input("ì§ˆë¬¸í•´ ì£¼ì„¸ìš”..."):
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        try:
            # ëŒ€í™” ê¸°ë¡ì„ í¬í•¨í•˜ì—¬ ë¬¸ë§¥ ìœ ì§€ (ìµœê·¼ 10ê°œë§Œ ë³´ë‚´ê¸° ë“± ìµœì í™” ê°€ëŠ¥)
            chat_history = [{"role": m["role"], "parts": [m["content"]]} for m in st.session_state.messages]
            
            response = model.generate_content(chat_history)
            full_response = response.text
            
            message_placeholder.markdown(full_response)
            st.session_state.messages.append({"role": "model", "content": full_response})
            
        except Exception as e:
            st.error(f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")