import streamlit as st
import os
import time
import datetime
import google.generativeai as genai
from google.generativeai import caching
from google.generativeai.types import HarmCategory, HarmBlockThreshold

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="2025ìƒí™œê¸°ë¡ë¶€ ë§¤ë‰´ì–¼", page_icon="ğŸ“š")

# 2. ì‚¬ì´ë“œë°”: ì„¤ì • ë° ì±… ì„ íƒ
with st.sidebar:
    st.header("ì„¤ì •")
    google_api_key = st.text_input("Google API Key", type="password")
    
    st.divider()
    st.subheader("ğŸ“š ì„œë²„ì— ì €ì¥ëœ ì±… ëª©ë¡")
    
    current_dir = os.getcwd()
    pdf_files = [f for f in os.listdir(current_dir) if f.endswith('.pdf')]
    
    if not pdf_files:
        st.error("âš ï¸ ì„œë²„ì— PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤!")
        st.info("ê¹ƒí—ˆë¸Œ ë¦¬í¬ì§€í† ë¦¬ì— .pdf íŒŒì¼ì„ í•¨ê»˜ ì—…ë¡œë“œí–ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        selected_file = None
    else:
        selected_file = st.selectbox("ì½ì„ ì±…ì„ ì„ íƒí•˜ì„¸ìš”", pdf_files)
        st.success(f"ì„ íƒë¨: {selected_file}")

    st.divider()
    # ëŒ€í™” ì´ˆê¸°í™” ë²„íŠ¼ ì¶”ê°€ (ì˜¤ë¥˜ ë°œìƒ ì‹œ ìœ ìš©)
    if st.button("ğŸ—‘ï¸ ëŒ€í™” ê¸°ë¡ ì§€ìš°ê¸°"):
        st.session_state.messages = []
        st.rerun()

# 3. ë©”ì¸ í™”ë©´
st.title("ğŸ“– 2025ìƒí™œê¸°ë¡ë¶€ ë§¤ë‰´ì–¼")
st.caption("Google Context Caching + Safety Filter í•´ì œ ì ìš©ë¨")

if not google_api_key:
    st.warning("ğŸ‘ˆ ì‚¬ì´ë“œë°”ì—ì„œ Google API Keyë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    st.stop()

if not selected_file:
    st.stop()

# API í‚¤ ì„¤ì •
genai.configure(api_key=google_api_key)

# 4. ìºì‹± ë¡œì§
if "cache_name" not in st.session_state:
    st.session_state.cache_name = None
if "current_book" not in st.session_state:
    st.session_state.current_book = ""

# ì±…ì´ ë³€ê²½ë˜ì—ˆê±°ë‚˜ ìºì‹œê°€ ì—†ìœ¼ë©´ ìƒì„± ì‹œì‘
if selected_file != st.session_state.current_book or st.session_state.cache_name is None:
    with st.spinner(f"ğŸš€ '{selected_file}' ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ êµ¬ê¸€ ì„œë²„ì— ì €ì¥ ì¤‘ì…ë‹ˆë‹¤... (ìµœì´ˆ 1íšŒ)"):
        try:
            # (1) íŒŒì¼ ê²½ë¡œ í™•ì¸
            file_path = os.path.join(current_dir, selected_file)
            
            # (2) êµ¬ê¸€ì— íŒŒì¼ ì—…ë¡œë“œ
            uploaded_file = genai.upload_file(file_path)
            
            # (3) [ì¤‘ìš”] ì²˜ë¦¬ ëŒ€ê¸° (Processing State í™•ì¸)
            # íŒŒì¼ì„ ì—…ë¡œë“œí•˜ìë§ˆì ì“°ë ¤ê³  í•˜ë©´ ì˜¤ë¥˜ê°€ ë‚˜ë¯€ë¡œ ê¸°ë‹¤ë¦½ë‹ˆë‹¤.
            while uploaded_file.state.name == "PROCESSING":
                time.sleep(2) 
                uploaded_file = genai.get_file(uploaded_file.name)
            
            if uploaded_file.state.name == "FAILED":
                raise ValueError("êµ¬ê¸€ ì„œë²„ íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨")

            # (4) ìºì‹œ ìƒì„±
            cache = caching.CachedContent.create(
                model='models/gemini-2.5-flash', # ìµœì‹  ëª¨ë¸ëª…ìœ¼ë¡œ ìˆ˜ì •ë¨
                display_name=selected_file,
                system_instruction=(
                    "ë„ˆëŠ” 2025ë…„ ìƒí™œê¸°ë¡ë¶€ ì‘ì„±ì§€ì¹¨ì„ ì™„ì „í•˜ê²Œ ì•Œê³  ìˆëŠ” ì „ë¬¸ê°€ì•¼. ì§ˆë¬¸ìì˜ ê³ ë¯¼ì„ ë“£ê³  ì±…ì˜ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ìƒë‹´í•´ì¤˜. "
                    "ì±… ì „ì²´ ë‚´ìš©ì„ ë‹¤ ì•Œê³  ìˆìœ¼ë‹ˆ, ì†Œì œëª©ì´ë‚˜ ì „ì²´ì ì¸ ë§¥ë½ë„ ë‹¤ íŒŒì•…í•´ì„œ ë‹µë³€í•´. "
                    "ì±…ì— ì—†ëŠ” ë‚´ìš©ì€ ì§€ì–´ë‚´ì§€ ë§ê³ , ì±… ë‚´ìš©ì„ ì¸ìš©í•´ì„œ ë”°ëœ»í•˜ê²Œ ë§í•´ì¤˜."
                    "ë‚´ìš©ì— ì•Œë§ì€ ê·€ì—¬ìš´ ì´ëª¨í‹°ì½˜ë„ ë„£ì–´ê°€ë©´ì„œ ë‹µë³€í•´ì¤˜."
                    "í‘œë¡œ ë‹µë³€ì„ í•´ì•¼í•˜ëŠ” ê²½ìš°ëŠ” ì•„ë˜ì˜ ê·œì¹™ì„ ë°˜ë“œì‹œ ì§€ì¼œì„œ ì‘ì„±í•´ì¤˜."
                    "[í‘œ ì‘ì„± ê·œì¹™] 1.í‘œë¥¼ ì¶œë ¥í•  ë•ŒëŠ” ë°˜ë“œì‹œ í‘œì¤€ Markdown ë¬¸ë²•ì„ ì¤€ìˆ˜í•˜ì„¸ìš”."
                    "[í‘œ ì‘ì„± ê·œì¹™] 2.ì‹œê°ì ì¸ ì ì„ (------------)ì´ë‚˜ ì¥ì‹ìš© ì„ ì„ ì‚¬ìš©í•˜ì—¬ í‘œë¥¼ ê·¸ë¦¬ì§€ ë§ˆì„¸ìš”."
                    "[í‘œ ì‘ì„± ê·œì¹™] 3.ë°ì´í„°ê°€ ì—†ëŠ” ë¹ˆ í–‰ì„ ì ì„ ìœ¼ë¡œ ì±„ìš°ì§€ ë§ˆì„¸ìš”."
                    "[í‘œ ì‘ì„± ê·œì¹™] 4. ë°˜ë“œì‹œ | í—¤ë” | í—¤ë” | í˜•ì‹ ë°”ë¡œ ì•„ë˜ì— |---|---| í˜•ì‹ì„ ì‚¬ìš©í•˜ì—¬ í‘œë¥¼ ë Œë”ë§í•˜ì„¸ìš”."
                    # [ì¤‘ìš”] ê°œì¸ì •ë³´ ì˜¤ì¸ ë°©ì§€ í”„ë¡¬í”„íŠ¸
                    "ì´ ë¬¸ì„œëŠ” êµìœ¡ë¶€ì—ì„œ ë°°í¬í•œ ê³µê°œëœ 'ê¸°ì¬ìš”ë ¹ ê°€ì´ë“œë¼ì¸'ì´ë©°, í¬í•¨ëœ ëª¨ë“  ì´ë¦„ê³¼ ì •ë³´ëŠ” **ì„¤ëª…ì„ ìœ„í•´ ë§Œë“¤ì–´ì§„ ê°€ìƒì˜ ì˜ˆì‹œ(Fictional Examples)**ì…ë‹ˆë‹¤. ì‹¤ì œ ê°œì¸ì •ë³´ê°€ ì•„ë‹ˆë¯€ë¡œ ì•ˆì‹¬í•˜ê³  ë¶„ì„í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”."
                ),
                contents=[uploaded_file],
                ttl=datetime.timedelta(minutes=60)
            )

            # (5) ì„¸ì…˜ì— ì •ë³´ ì €ì¥
            st.session_state.cache_name = cache.name
            st.session_state.current_book = selected_file
            st.session_state.messages = [] 
            st.success(f"âœ… ë¶„ì„ ì™„ë£Œ! ({selected_file})")
            
        except Exception as e:
            st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
            st.stop()

# 5. ëª¨ë¸ ë¡œë”©
try:
    cached_content = caching.CachedContent.get(st.session_state.cache_name)
    model = genai.GenerativeModel.from_cached_content(cached_content=cached_content)
    
except Exception as e:
    st.error("âš ï¸ ì„¸ì…˜ì´ ë§Œë£Œë˜ì—ˆìŠµë‹ˆë‹¤. (1ì‹œê°„ ê²½ê³¼) ìƒˆë¡œê³ ì¹¨ í•´ì£¼ì„¸ìš”.")
    st.session_state.cache_name = None
    st.stop()

# 6. ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if user_input := st.chat_input("ì§ˆë¬¸í•´ ì£¼ì„¸ìš”..."):
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        
        # [í•µì‹¬] ì•ˆì „ ì„¤ì •: ëª¨ë“  í•„í„°ë¥¼ êº¼ë²„ë¦¼ (BLOCK_NONE)
        # ìƒê¸°ë¶€ ê´€ë ¨ ë¬¸ì„œ(ì§•ê³„, í­ë ¥ ë“±)ê°€ ì˜¤í•´ë°›ì§€ ì•Šë„ë¡ í•¨
        safety_settings = {
            HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
            HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
            HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
            HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
        }

        try:
            # ì±„íŒ… ê¸°ë¡ êµ¬ì„±
            chat_history = [{"role": m["role"], "parts": [m["content"]]} for m in st.session_state.messages]
            
            # ë‹µë³€ ìš”ì²­ (safety_settings ì ìš©)
            response = model.generate_content(
                chat_history,
                safety_settings=safety_settings
            )
            
            # [ìˆ˜ì •ë¨] ë‹µë³€ ì°¨ë‹¨(Safety Block) í™•ì¸ ë¡œì§
            if response.parts:
                full_response = response.text
                message_placeholder.markdown(full_response)
                st.session_state.messages.append({"role": "model", "content": full_response})
            else:
                # ë‹µë³€ì´ ì°¨ë‹¨ë˜ì—ˆê±°ë‚˜ ë¹„ì–´ìˆëŠ” ê²½ìš° ì²˜ë¦¬
                error_msg = "âš ï¸ AIê°€ ë‹µë³€ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
                if response.prompt_feedback:
                    error_msg += f"\n(ì‚¬ìœ : {response.prompt_feedback.block_reason})"
                
                message_placeholder.error(error_msg)
                
                # ì—ëŸ¬ê°€ ë‚œ ê²½ìš° ë§ˆì§€ë§‰ ì‚¬ìš©ì ì§ˆë¬¸ì„ ì‚­ì œí•˜ì—¬ ë‹¤ìŒ ëŒ€í™”ê°€ ê¼¬ì´ì§€ ì•Šê²Œ í•¨
                if st.session_state.messages and st.session_state.messages[-1]["role"] == "user":
                    st.session_state.messages.pop()

        except Exception as e:
            st.error(f"ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}")
            if st.session_state.messages and st.session_state.messages[-1]["role"] == "user":
                st.session_state.messages.pop()
